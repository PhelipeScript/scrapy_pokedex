# PokÃ©dex Scraper

Um web scraper desenvolvido em Python usando Scrapy para extrair informaÃ§Ãµes completas de PokÃ©mons do site [PokemonDB](https://pokemondb.net/pokedex/all) e armazenÃ¡-las em MongoDB.

## ğŸ“‹ Funcionalidades

Este scraper coleta as seguintes informaÃ§Ãµes de cada PokÃ©mon:

### Dados BÃ¡sicos
- âœ… **NÃºmero do PokÃ©dex**
- âœ… **Nome e apelido** (se houver)
- âœ… **URL da pÃ¡gina**
- âœ… **Tipos** (Ãgua, Fogo, Grama, etc.)
- âœ… **Altura** (em centÃ­metros)
- âœ… **Peso** (em quilogramas)

### EvoluÃ§Ãµes
- âœ… **PrÃ³ximas evoluÃ§Ãµes** (se houver)
  - NÃºmero do PokÃ©dex
  - Nome e apelido
  - Requisito de evoluÃ§Ã£o (nÃ­vel, item, etc.)
  - URL da pÃ¡gina

### Efetividade de Tipos
- âœ… **Tabela de efetividade** contra todos os tipos
- âœ… **Diferentes habilidades** (quando aplicÃ¡vel)

### Habilidades
- âœ… **Nome da habilidade**
- âœ… **DescriÃ§Ã£o completa**
- âœ… **Habilidades ocultas**
- âœ… **URL da pÃ¡gina da habilidade**

## ğŸ› ï¸ Tecnologias Utilizadas

- **Python 3.12**
- **Scrapy** - Framework para web scraping
- **MongoDB** - Banco de dados NoSQL
- **PyMongo** - Driver MongoDB para Python

## ğŸ“¦ InstalaÃ§Ã£o

1. **Clone o repositÃ³rio:**
```bash
git clone <url-do-repositorio>
cd pokemon-scraper
```

2. **Instale as dependÃªncias usando Pipenv:**
```bash
pipenv install
```

3. **Ative o ambiente virtual:**
```bash
pipenv shell
```

4. **Configure a conexÃ£o MongoDB:**
   - Edite o arquivo `mongodb.py` com suas credenciais do MongoDB
   - Ou configure as variÃ¡veis de ambiente necessÃ¡rias

## ğŸš€ Como Usar

### ExecuÃ§Ã£o BÃ¡sica

```bash
python main.py
```

### Fluxo de ExecuÃ§Ã£o

1. **Scraping**: O spider navega pelo PokÃ©dex coletando dados de todos os PokÃ©mons
2. **Processamento**: Os dados sÃ£o processados e salvos em `pokemons.json`
3. **Armazenamento**: Os dados sÃ£o inseridos no MongoDB
4. **AnÃ¡lises**: Executa consultas de exemplo nos dados coletados

### SaÃ­da do Console

O programa exibe informaÃ§Ãµes coloridas durante a execuÃ§Ã£o:
- ğŸ” **Cyan**: Buscando dados bÃ¡sicos do PokÃ©mon
- ğŸ” **Blue**: Coletando efetividade de tipos
- ğŸ” **Magenta**: Extraindo habilidades
- ğŸ” **Green**: Processando evoluÃ§Ãµes

## ğŸ“Š Estrutura dos Dados

### Formato JSON de SaÃ­da

```json
{
  "pokemon_id": {
    "number": "001",
    "name": "Bulbasaur",
    "nickname": null,
    "url": "https://pokemondb.net/pokedex/bulbasaur",
    "types": ["Grass", "Poison"],
    "height_cm": 70,
    "weight_kg": 6.9,
    "evolutions": [
      {
        "unique_id": "002_ivysaur",
        "numero": "002",
        "name": "Ivysaur",
        "nickname": null,
        "requirement": "Level 16",
        "url": "https://pokemondb.net/pokedex/ivysaur"
      }
    ],
    "effectiveness": {
      "default_ability": {
        "Fire": 2,
        "Water": 0.5,
        "Electric": 0.5,
        "Grass": 0.25
      }
    },
    "abilities": {
      "overgrow": {
        "name": "Overgrow",
        "description": "Powers up Grass-type moves when the PokÃ©mon's HP is low.",
        "is_hidden_ability": false,
        "url": "https://pokemondb.net/ability/overgrow"
      }
    }
  }
}
```

### Estrutura no MongoDB

Os dados sÃ£o armazenados no MongoDB com a seguinte estrutura:
- **Database**: `pokedex`
- **Collection**: `pokemons`
- **_id**: ID Ãºnico do PokÃ©mon
- **Campos**: Todos os dados coletados do scraping

## ğŸ” Consultas de Exemplo

O cÃ³digo inclui algumas consultas de anÃ¡lise:

### 1. PokÃ©mons com MÃºltiplos Tipos
```python
# Conta PokÃ©mons com 2 ou mais tipos
count = db.count_pokemons_by_min_types(2)
```

### 2. EvoluÃ§Ãµes por Tipo e NÃ­vel
```python
# Busca PokÃ©mons do tipo Ãgua que evoluem apÃ³s nÃ­vel 30
water_pokemons = db.fetch_evolutions_of_type_after_level("Water", 30)
```

## ğŸ“ Estrutura do Projeto

```
pokemon-scraper/
â”œâ”€â”€ main.py              # Spider principal e lÃ³gica de scraping
â”œâ”€â”€ mongodb.py           # Classe para interaÃ§Ã£o com MongoDB
â”œâ”€â”€ colors.py            # Constantes para cores no terminal
â”œâ”€â”€ Pipfile             # DependÃªncias do projeto
â”œâ”€â”€ Pipfile.lock        # VersÃµes especÃ­ficas das dependÃªncias
â”œâ”€â”€ .gitignore          # Arquivos ignorados pelo Git
â”œâ”€â”€ README.md           # Este arquivo
â””â”€â”€ pokemons.json       # Arquivo de saÃ­da (gerado apÃ³s execuÃ§Ã£o)
```

## âš™ï¸ ConfiguraÃ§Ãµes Personalizadas

### ConfiguraÃ§Ãµes do Scrapy

O spider possui configuraÃ§Ãµes customizadas:
- **Formato de saÃ­da**: JSON com encoding UTF-8
- **Log level**: ERROR (para reduzir verbosidade)
- **IndentaÃ§Ã£o**: 2 espaÃ§os para melhor legibilidade

### Tratamento de Casos Especiais

- **PokÃ©mons com formas alternativas** (ex: Alolan, Galarian)
- **EvoluÃ§Ãµes com requisitos especiais** (pedras, trocas, itens)
- **PokÃ©mons com mÃºltiplas habilidades**
- **Eevee e suas mÃºltiplas evoluÃ§Ãµes**

## ğŸ› Tratamento de Erros

- **Dados ausentes**: Valores nulos para campos nÃ£o encontrados
- **URLs invÃ¡lidas**: VerificaÃ§Ã£o de links antes do processamento
- **ConexÃ£o de rede**: Retry automÃ¡tico do Scrapy
- **Dados malformados**: Limpeza e validaÃ§Ã£o de strings

## ğŸ“ˆ Performance

- **Rate limiting**: Configurado para ser respeitoso com o servidor
- **Caching**: Evita requisiÃ§Ãµes duplicadas
- **Processamento assÃ­ncrono**: Utiliza a natureza assÃ­ncrona do Scrapy

## ğŸ¤ Contribuindo

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/nova-feature`)
3. Commit suas mudanÃ§as (`git commit -am 'Adiciona nova feature'`)
4. Push para a branch (`git push origin feature/nova-feature`)
5. Abra um Pull Request

## âš ï¸ Disclaimer

Este projeto Ã© apenas para fins educacionais e de pesquisa. Sempre respeite os termos de uso dos sites que vocÃª estÃ¡ fazendo scraping e use prÃ¡ticas Ã©ticas de web scraping.

## ğŸ“ Suporte

Se vocÃª encontrar algum problema ou tiver sugestÃµes, por favor abra uma [issue](../../issues) no repositÃ³rio.
